{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/Coastal Data System - Waves (Mooloolaba) 01-2017 to 06 - 2019.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(-99.90, np.nan, inplace=True)\n",
    "df.drop('Date/Time',axis=1,inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_graph = df.loc[0:100]\n",
    "\n",
    "plt.figure(figsize=(15,22))\n",
    "plt.subplot(6,2,1)\n",
    "plt.plot(df_graph['Hs'],color='blue')\n",
    "plt.title('Significant Wave Height')\n",
    "\n",
    "plt.subplot(6,2,2)\n",
    "plt.plot(df_graph['Hmax'],color='red')\n",
    "plt.title('Maximum Wave Height')\n",
    "\n",
    "plt.subplot(6,2,3)\n",
    "plt.plot(df_graph['Tz'],color='orange')\n",
    "plt.title(\"Zero Upcrossing Wave Period\")\n",
    "\n",
    "plt.subplot(6,2,4)\n",
    "plt.plot(df_graph['Tp'],color='brown')\n",
    "plt.title(\"The Peak Energy Wave Period\")\n",
    "\n",
    "plt.subplot(6,2,5)\n",
    "plt.plot(df_graph['Peak Direction'],color='purple')\n",
    "plt.title(\"Direction related to True North\")\n",
    "\n",
    "plt.subplot(6,2,6)\n",
    "plt.plot(df_graph['SST'],color='green')\n",
    "plt.title(\"Sea Surface Temperature\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "sns.heatmap(df.corr(),linewidth=.1,annot=True,cmap=\"YlGnBu\")\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#Scaling all values between 1 and 0\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "data = scaler.fit_transform(df)\n",
    "print('Shape of the scaled data matrix: ',data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Test Split\n",
    "\n",
    "train = data[:42000,]\n",
    "test = data[42000: ,]\n",
    "\n",
    "#Check the shapes of the datasets\n",
    "print('Shape of train data: ',train.shape)\n",
    "print('Shape of test data: ',test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_dataset(dataset,lookback):\n",
    "    \"\"\"\n",
    "    Transform the dataset array into a torch tensor\n",
    "    \"\"\"\n",
    "    X_, y_ = [],[]\n",
    "    for i in range(len(dataset) - lookback - 1):\n",
    "        feature = dataset[i:i+lookback]\n",
    "        target = dataset[i+lookback+1]\n",
    "        X_.append(feature)\n",
    "        y_.append(target)\n",
    "        \n",
    "    X = np.array(X_)\n",
    "    X = np.reshape(X,(X.shape[0],X.shape[2],X.shape[1]))\n",
    "    y = np.array(y_)\n",
    "    return torch.tensor(X,dtype=torch.float32),torch.tensor(y,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback = 30\n",
    "\n",
    "X_train, y_train = create_dataset(train,lookback)\n",
    "X_test,y_test = create_dataset(test,lookback)\n",
    "\n",
    "print(f'X_train shape: {X_train.shape} , y_train shape :{y_train.shape}')\n",
    "print('X_test shape :',X_test.shape, ' y_test shape: ',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train.shape[1],X_train.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "\n",
    "class WaveLSTM(nn.Module):\n",
    "    def __init__(self, input_dim,hidden_dim1=32,hidden_dim2=16,hidden_dim3=10,output_dim=6,dropout=0.2):\n",
    "        super(WaveLSTM,self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_dim,hidden_dim1,batch_first=True,bidirectional=False)\n",
    "        self.lstm2 = nn.LSTM(hidden_dim1,hidden_dim2,batch_first=True,bidirectional=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.lstm3 = nn.LSTM(hidden_dim2,hidden_dim3,batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim3,output_dim)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out,_ = self.lstm1(x)\n",
    "        out,_ = self.lstm2(out)\n",
    "        out = self.dropout(out)\n",
    "        out,_ = self.lstm3(out)\n",
    "        out = self.fc(out[:, -1, :]) #Using the last time's step's out for the dense layer\n",
    "        return out\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "input_dim = 30\n",
    "\n",
    "model = WaveLSTM(input_dim).to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=1e-3)\n",
    "\n",
    "batch_size = 200\n",
    "train_dataset = TensorDataset(X_train,y_train)\n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
    "test_dataset = TensorDataset(X_test,y_test)\n",
    "test_loader = DataLoader(test_dataset,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "num_epochs = 15\n",
    "train_hist = []\n",
    "test_hist = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    model.train()\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X,batch_y = batch_X.to(device),batch_y.to(device)\n",
    "        predictions = model(batch_X)\n",
    "        loss = loss_fn(predictions,batch_y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    train_hist.append(average_loss)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        total_test_loss = 0.0\n",
    "        \n",
    "        for batch_X_test,batch_y_test in test_loader:\n",
    "            batch_X_test,batch_y_test = batch_X_test.to(device),batch_y_test.to(device)\n",
    "            test_pred = model(batch_X_test)\n",
    "            test_loss = loss_fn(test_pred,batch_y_test)\n",
    "            \n",
    "            total_test_loss += test_loss.item()\n",
    "        \n",
    "        average_test_loss = total_test_loss / len(test_loader)\n",
    "        test_hist.append(average_test_loss)\n",
    "    \n",
    "    print(f\"Epoch[{epoch + 1}/{num_epochs}] - Training Loss: {average_loss:.4f}, Test Loss: {average_test_loss}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(1,num_epochs,num_epochs)\n",
    "plt.plot(x,train_hist,scalex=True,label=\"Training loss\")\n",
    "plt.plot(x,test_hist,label=\"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAKING PREDICTIONS\n",
    "\n",
    "\n",
    "# Define the function for predictions\n",
    "def predicting(model, data, y_real, scaler):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Ensure no gradients are calculated during inference\n",
    "    with torch.no_grad():\n",
    "        # Perform prediction\n",
    "        predicted_data = model(data)\n",
    "    \n",
    "    # Invert scaling process to get the original value ranges\n",
    "    predicted_data = scaler.inverse_transform(predicted_data.numpy())\n",
    "    y_real = scaler.inverse_transform(y_real.numpy())\n",
    "    \n",
    "    return predicted_data, y_real\n",
    "\n",
    "# Execute predictions\n",
    "train_prediction, y_train_scaled = predicting(model, X_train, y_train, scaler)\n",
    "test_prediction, y_test_scaled = predicting(model, X_test, y_test, scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_prediction.shape,predictions.shape)\n",
    "train_prediction==y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def examine_rmse(y_true,y_pred):\n",
    "    Score_Hs = math.sqrt(mean_squared_error(y_true[:,0],   y_pred[:,0]))\n",
    "    Score_Hmax = math.sqrt(mean_squared_error(y_true[:,1], y_pred[:,1]))\n",
    "    Score_Tz = math.sqrt(mean_squared_error(y_true[:,2],   y_pred[:,2]))\n",
    "    Score_Tp = math.sqrt(mean_squared_error(y_true[:,3],   y_pred[:,3]))\n",
    "    Score_Dir = math.sqrt(mean_squared_error(y_true[:,4],  y_pred[:,4]))\n",
    "    Score_SST = math.sqrt(mean_squared_error(y_true[:,5],  y_pred[:,5]))\n",
    "    \n",
    "    print('RMSE_Hs       : ', Score_Hs)\n",
    "    print('RMSE_Hmax     : ', Score_Hmax)\n",
    "    print('RMSE_Tz       : ', Score_Tz)\n",
    "    print('RMSE_Tp       : ', Score_Tp)\n",
    "    print('RMSE_Direction: ', Score_Dir)\n",
    "    print('RMSE_SST      : ', Score_SST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executing the RMSE comparison\n",
    "print('Trainin Data Errors')\n",
    "print(examine_rmse(train_prediction, y_train_scaled),'\\n')\n",
    "print('Test Data Errors')\n",
    "print(examine_rmse(test_prediction, y_test_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(17,25))\n",
    "\n",
    "\n",
    "plt.subplot(6,2,1)\n",
    "plt.plot(test_prediction[1300:,0], color='red', alpha=0.7, label='prediction')\n",
    "plt.plot(y_test_scaled[1300:,0], color='blue', alpha=0.5, label='real')\n",
    "plt.title('Significant Wave Height')\n",
    "plt.legend()\n",
    "plt.grid(axis='y')\n",
    "\n",
    "plt.subplot(6,2,2)\n",
    "plt.plot(test_prediction[1300:,1], color='red', alpha=0.7, label='prediction')\n",
    "plt.plot(y_test_scaled[1300:,1], color='blue', alpha=0.5, label='real')\n",
    "plt.title('Maximum Wave Height')\n",
    "plt.legend()\n",
    "plt.grid(axis='y')\n",
    "\n",
    "plt.subplot(6,2,3)\n",
    "plt.plot(test_prediction[1300:,2], color='red', alpha=0.7, label='prediction')\n",
    "plt.plot(y_test_scaled[1300:,2], color='blue', alpha=0.5, label='real')\n",
    "plt.title('Zero Upcrossing Wave Period')\n",
    "plt.legend()\n",
    "plt.grid(axis='y')\n",
    "\n",
    "plt.subplot(6,2,4)\n",
    "plt.plot(test_prediction[1300:,3], color='red', alpha=0.7, label='prediction')\n",
    "plt.plot(y_test_scaled[1300:,3], color='blue', alpha=0.5, label='real')\n",
    "plt.title('Peak Energy Wave Period')\n",
    "plt.legend()\n",
    "plt.grid(axis='y')\n",
    "\n",
    "plt.subplot(6,2,5)\n",
    "plt.plot(test_prediction[1300:,4], color='red', alpha=0.7, label='prediction')\n",
    "plt.plot(y_test_scaled[1300:,4], color='blue', alpha=0.5, label='real')\n",
    "plt.title('Direction Related to True North')\n",
    "plt.legend()\n",
    "plt.grid(axis='y')\n",
    "\n",
    "plt.subplot(6,2,6)\n",
    "plt.plot(test_prediction[1300:,5], color='red', alpha=0.7, label='prediction')\n",
    "plt.plot(y_test_scaled[1300:,5], color='blue', alpha=0.5, label='real')\n",
    "plt.title('Sea Surface Temperature')\n",
    "plt.legend()\n",
    "plt.grid(axis='y')\n",
    "plt.show();\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
