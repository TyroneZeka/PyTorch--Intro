{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch \n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./mlp_img'):\n",
    "    os.mkdir('./mlp_img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_img(x):\n",
    "    x = 0.5 * (x + 1)\n",
    "    x = x.clamp(0,1)\n",
    "    x = x.view(x.size(0), 1, 28,28)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5), (0.5))\n",
    "])\n",
    "\n",
    "dataset = MNIST('./data', transform=img_transform)\n",
    "dataloader = DataLoader(dataset,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder,self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128,64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64,12),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(12,3),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3,12),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(12,64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64,128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128,28 * 28),\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.encoder(x)\n",
    "        out = self.decoder(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[1/100], loss: 0.1988\n",
      "epoch[2/100], loss: 0.1805\n",
      "epoch[3/100], loss: 0.1841\n",
      "epoch[4/100], loss: 0.1668\n",
      "epoch[5/100], loss: 0.1617\n",
      "epoch[6/100], loss: 0.1495\n",
      "epoch[7/100], loss: 0.1636\n",
      "epoch[8/100], loss: 0.1548\n",
      "epoch[9/100], loss: 0.1605\n",
      "epoch[10/100], loss: 0.1404\n",
      "epoch[11/100], loss: 0.1488\n",
      "epoch[12/100], loss: 0.1532\n",
      "epoch[13/100], loss: 0.1539\n",
      "epoch[14/100], loss: 0.1514\n",
      "epoch[15/100], loss: 0.1448\n",
      "epoch[16/100], loss: 0.1544\n",
      "epoch[17/100], loss: 0.1450\n",
      "epoch[18/100], loss: 0.1371\n",
      "epoch[19/100], loss: 0.1491\n",
      "epoch[20/100], loss: 0.1429\n",
      "epoch[21/100], loss: 0.1336\n",
      "epoch[22/100], loss: 0.1414\n",
      "epoch[23/100], loss: 0.1393\n",
      "epoch[24/100], loss: 0.1561\n",
      "epoch[25/100], loss: 0.1470\n",
      "epoch[26/100], loss: 0.1415\n",
      "epoch[27/100], loss: 0.1454\n",
      "epoch[28/100], loss: 0.1495\n",
      "epoch[29/100], loss: 0.1327\n",
      "epoch[30/100], loss: 0.1390\n",
      "epoch[31/100], loss: 0.1323\n",
      "epoch[32/100], loss: 0.1475\n",
      "epoch[33/100], loss: 0.1389\n",
      "epoch[34/100], loss: 0.1380\n",
      "epoch[35/100], loss: 0.1494\n",
      "epoch[36/100], loss: 0.1369\n",
      "epoch[37/100], loss: 0.1342\n",
      "epoch[38/100], loss: 0.1421\n",
      "epoch[39/100], loss: 0.1309\n",
      "epoch[40/100], loss: 0.1324\n",
      "epoch[41/100], loss: 0.1421\n",
      "epoch[42/100], loss: 0.1272\n",
      "epoch[43/100], loss: 0.1280\n",
      "epoch[44/100], loss: 0.1268\n",
      "epoch[45/100], loss: 0.1224\n",
      "epoch[46/100], loss: 0.1373\n",
      "epoch[47/100], loss: 0.1282\n",
      "epoch[48/100], loss: 0.1380\n",
      "epoch[49/100], loss: 0.1337\n",
      "epoch[50/100], loss: 0.1302\n",
      "epoch[51/100], loss: 0.1318\n",
      "epoch[52/100], loss: 0.1405\n",
      "epoch[53/100], loss: 0.1416\n",
      "epoch[54/100], loss: 0.1278\n",
      "epoch[55/100], loss: 0.1218\n",
      "epoch[56/100], loss: 0.1376\n",
      "epoch[57/100], loss: 0.1218\n",
      "epoch[58/100], loss: 0.1346\n",
      "epoch[59/100], loss: 0.1371\n",
      "epoch[60/100], loss: 0.1328\n",
      "epoch[61/100], loss: 0.1395\n",
      "epoch[62/100], loss: 0.1342\n",
      "epoch[63/100], loss: 0.1219\n",
      "epoch[64/100], loss: 0.1354\n",
      "epoch[65/100], loss: 0.1302\n",
      "epoch[66/100], loss: 0.1186\n",
      "epoch[67/100], loss: 0.1315\n",
      "epoch[68/100], loss: 0.1345\n",
      "epoch[69/100], loss: 0.1292\n",
      "epoch[70/100], loss: 0.1317\n",
      "epoch[71/100], loss: 0.1352\n",
      "epoch[72/100], loss: 0.1423\n",
      "epoch[73/100], loss: 0.1403\n",
      "epoch[74/100], loss: 0.1411\n",
      "epoch[75/100], loss: 0.1348\n",
      "epoch[76/100], loss: 0.1281\n",
      "epoch[77/100], loss: 0.1335\n",
      "epoch[78/100], loss: 0.1315\n",
      "epoch[79/100], loss: 0.1356\n",
      "epoch[80/100], loss: 0.1280\n",
      "epoch[81/100], loss: 0.1440\n",
      "epoch[82/100], loss: 0.1267\n",
      "epoch[83/100], loss: 0.1337\n",
      "epoch[84/100], loss: 0.1231\n",
      "epoch[85/100], loss: 0.1326\n",
      "epoch[86/100], loss: 0.1328\n",
      "epoch[87/100], loss: 0.1511\n",
      "epoch[88/100], loss: 0.1382\n",
      "epoch[89/100], loss: 0.1343\n",
      "epoch[90/100], loss: 0.1261\n",
      "epoch[91/100], loss: 0.1296\n",
      "epoch[92/100], loss: 0.1314\n",
      "epoch[93/100], loss: 0.1262\n",
      "epoch[94/100], loss: 0.1253\n",
      "epoch[95/100], loss: 0.1349\n",
      "epoch[96/100], loss: 0.1388\n",
      "epoch[97/100], loss: 0.1427\n",
      "epoch[98/100], loss: 0.1277\n",
      "epoch[99/100], loss: 0.1295\n",
      "epoch[100/100], loss: 0.1294\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = autoencoder().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),lr=learning_rate,weight_decay=1e-5,\n",
    ")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for data in dataloader:\n",
    "        img,_ = data\n",
    "        img = img.view(img.size(0),-1)\n",
    "        img = Variable(img).to(device)\n",
    "        #=====================FORWARD PASS================================\n",
    "        output = model(img)\n",
    "        loss = loss_fn(output,img)\n",
    "        \n",
    "        #+++++++++++++++++++++BACKWARD PASS++++++++++++++++++++++++++++++++\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    #*********************LOGGING**************************************\n",
    "    print('epoch[{}/{}], loss: {:.4f}'.format(epoch + 1,num_epochs,loss.item()))\n",
    "    if epoch % 10 == 0:\n",
    "        if torch.cuda.is_available():\n",
    "            pic = to_img(output.cpu().data)\n",
    "        else:\n",
    "            pic = to_img(output.data)\n",
    "        save_image(pic,'./mlp_img/image_{}.png'.format(epoch))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "MODEL_PATH = Path(\"saved_models\")\n",
    "MODEL_PATH.mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "#Create model save path\n",
    "MODEL_NAME = \"simple_autoencoder.pth\"\n",
    "MODEL_SAVE_PATH= MODEL_PATH / MODEL_NAME\n",
    "\n",
    "#Save the state dict\n",
    "torch.save(obj=model.state_dict(),\n",
    "           f=MODEL_SAVE_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
